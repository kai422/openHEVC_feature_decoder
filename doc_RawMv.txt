STEP1: create memory buffer

libavutil/frame.h:158
    //MvDecoder: change 8 to 12 (must bigger than used size)
#define AV_NUM_DATA_POINTERS 12

libavutil/imgutils.c:107
    //MvDecoder linesizes
    linesizes[3]=0;
    linesizes[4]=0;
    linesizes[5]=0;
    linesizes[6]=0;
    linesizes[7]=0;
    linesizes[8]=0;
    linesizes[9]=0;
    linesizes[10]=0;

????
libavcodec/hevc.c:377
    for (i = 0; frame->data[i]; i++) {
        int offset = frame->linesize[i] + (1 << sps->pixel_shift);
        frame->data[i] += offset;
    }
    frame->width  = s->avctx->width;
    frame->height = s->avctx->height;
????

libavcodec/internal.h:53
    // MvDecoder: get buffer pool for MVX, MVY
    // changed 4 to 11 for more space holding features.
    // pools[0-2]: Y U V
    // pools[3-4]: raw MVX, MVY for L0
    // pools[5-6]: raw MVX, MVY for L1
    // pools[7]: MV reference frame offset L0
    // pools[8]: MV reference frame offset L1
    // pools[9]: frame cu byte size
    // pools[10]: frame meta_information + partition quadtree structure.
    AVBufferPool *pools[11];


libavcodec/internal.h:70
    // MvDecoder
    int linesize[12];


libavcodec/utils.c:518
    //MvDecoder: buffer size array.
    int size[11] = { 0 };

libavcodec/utils.c:555
    //MvDecoder: mem pool size for raw motion vector x and y int16_t
    size[3] = size[0]*2; //mv_x for L0
    size[4] = size[0]*2; //mv_y for L0
    size[5] = size[0]*2; //mv_x for L1
    size[6] = size[0]*2; //mv_y for L1
    //MvDecoder: mem pool size for mv reference frame offset. u_int8_t
    size[7] = size[0]; //refer offset for L0
    size[8] = size[0]; //refer offset for L0
    //MvDecoder: mem pool size for cu byte size density.
    size[9] = size[0];
    //MvDecoder: mem pool size for frame meta_information
    //0: I_frame/P_frame/B_frame
    //1-1023: Other meta_information(e.g. size)
    //1024-65536: quadtree structure, for each CTU 21 bits/3bytes needed.
    size[10] = 65536;


    //MvDecoder: change i < 3 to i < 11 to allocate buffer space for hevc structure feature.
    for (i = 0; i < 11; i++) {

libavcodec/utils.c:692
    // MvDecoder: change 3 to 11. Originally buffer has 3 channel. Now add two more channel for motion vector and other features.
    for (i = 0; i < 11 && pool->pools[i]; i++) {



libavutil/imgutils.c:160
    //MvDecoder:
    data[3] = data[2] + size[0]*2;
    data[4] = data[3] + size[0]*2;
    data[5] = data[4] + size[0]*2;
    data[6] = data[5] + size[0]*2;
    data[7] = data[6] + size[0];
    data[8] = data[7] + size[0];
    data[9] = data[8] + size[0];
    data[10] = data[9] + 8192;








    // Now we have the buffer for mv and other features to fill in for the decoding stage









STEP2: save features to the buffers
libavcodec/hevc.c:2207
    // MvDecoder: get motion vector buffer dst pixel offset.
    u_long pixel_offset = ((y0) >> s->sps->vshift[0]) * s->frame->linesize[0] + (((x0) >> s->sps->hshift[0]) << s->sps->pixel_shift);

libavcodec/hevc.c:2358
PF_LO:
    // MvDecoder: write motion vector value into buffer.
    MvDecoder_write_mv_buffer(s, pixel_offset, s->frame->linesize[0],ref0->frame, NULL,
                                  &current_mv, nPbW, nPbH);
libavcodec/hevc.c:2380
PF_L1:
    // MvDecoder: write motion vector value into buffer.
    MvDecoder_write_mv_buffer(s, pixel_offset, s->frame->linesize[0], NULL, ref1->frame,
                              &current_mv, nPbW, nPbH);
libavcodec/hevc.c:2399
PF_BI:
    // MvDecoder: write motion vector value into buffer.
    MvDecoder_write_mv_buffer(s, pixel_offset, s->frame->linesize[0], ref0->frame, ref1->frame,
                              &current_mv, nPbW, nPbH);


libavcodec/hevc.c:1865
    static void MvDecoder_write_mv_buffer(HEVCContext *s, u_long pixel_offset, ptrdiff_t dststride,
                            AVFrame *ref0, AVFrame *ref1, struct MvField *current_mv,
                            int block_w, int block_h)
    {
        int16_t *MvDecoder_dst_mvx_L0 = (int16_t*)&s->frame->data[3][pixel_offset*2]; //uint8_t(1_byte) to int16_t(2_byte)
        int16_t *MvDecoder_dst_mvy_L0 = (int16_t*)&s->frame->data[4][pixel_offset*2]; //uint8_t(1_byte) to int16_t(2_byte)
        int16_t *MvDecoder_dst_mvx_L1 = (int16_t*)&s->frame->data[5][pixel_offset*2]; //uint8_t(1_byte) to int16_t(2_byte)
        int16_t *MvDecoder_dst_mvy_L1 = (int16_t*)&s->frame->data[6][pixel_offset*2]; //uint8_t(1_byte) to int16_t(2_byte)
        u_int8_t *MvDecoder_dst_ref_offset_L0 = &s->frame->data[7][pixel_offset]; // backward offset L0
        u_int8_t *MvDecoder_dst_ref_offset_L1 = &s->frame->data[8][pixel_offset]; // forward offset L1


        ptrdiff_t srcstride;
        if (current_mv->pred_flag == PF_L0) {
            srcstride  = ref0->linesize[0];
        }
        else if(current_mv->pred_flag == PF_L1) {
            srcstride  = ref1->linesize[0];
        }
        else if(current_mv->pred_flag == PF_BI) {
            srcstride  = ref0->linesize[0];
        }
        int pic_width        = s->sps->width;
        int pic_height       = s->sps->height;
        //亚像素的运动矢量
        //mv0,mv1单位是1/4像素
        //reverse motion vector sign if refer backwards


        if (current_mv->pred_flag == PF_L0) {
            const Mv *mv            = &current_mv->mv[0];
            int16_t mx              = mv->x;
            int16_t my              = mv->y;
            u_int8_t refer_offset = s->poc - current_mv->poc[0];
            int x, y;
            //处理x*y个像素
            for (y = 0; y < block_h; y++) {
                for (x = 0; x < block_w; x++) {
                    MvDecoder_dst_mvx_L0[x] = mx;
                    MvDecoder_dst_mvy_L0[x] = my;
                    MvDecoder_dst_ref_offset_L0[x] = refer_offset;
                }
                MvDecoder_dst_mvx_L0 += dststride;
                MvDecoder_dst_mvy_L0 += dststride;
                MvDecoder_dst_ref_offset_L0 += dststride;
            }
        }
        else if(current_mv->pred_flag == PF_L1) {
            const Mv *mv            = &current_mv->mv[1];
            int16_t mx              = mv->x;
            int16_t my              = mv->y;
            u_int8_t refer_offset =  current_mv->poc[1] - s->poc;
            int x, y;
            //处理x*y个像素
            for (y = 0; y < block_h; y++) {
                for (x = 0; x < block_w; x++) {
                    MvDecoder_dst_mvx_L1[x] = mx;
                    MvDecoder_dst_mvy_L1[x] = my;
                    MvDecoder_dst_ref_offset_L1[x] = refer_offset;
                }
                MvDecoder_dst_mvx_L1 += dststride;
                MvDecoder_dst_mvy_L1 += dststride;
                MvDecoder_dst_ref_offset_L1 += dststride;
            }
        }
        else if(current_mv->pred_flag == PF_BI) {
            const Mv *mv0           = &current_mv->mv[0];
            const Mv *mv1           = &current_mv->mv[1];
            int16_t mx0              = mv0->x;
            int16_t my0              = mv0->y;
            int16_t mx1              = mv1->x;
            int16_t my1              = mv1->y;
            u_int8_t refer_offset0 = s->poc - current_mv->poc[0];
            u_int8_t refer_offset1 = current_mv->poc[1] - s->poc;

            int x, y;
            //处理x*y个像素
            for (y = 0; y < block_h; y++) {
                for (x = 0; x < block_w; x++) {
                    MvDecoder_dst_mvx_L0[x] = mx0;
                    MvDecoder_dst_mvy_L0[x] = my0;
                    MvDecoder_dst_ref_offset_L0[x] = refer_offset0;
                    MvDecoder_dst_mvx_L1[x] = mx1;
                    MvDecoder_dst_mvy_L1[x] = my1;
                    MvDecoder_dst_ref_offset_L1[x] = refer_offset1;
                }
                MvDecoder_dst_mvx_L0 += dststride;
                MvDecoder_dst_mvy_L0 += dststride;
                MvDecoder_dst_ref_offset_L0 += dststride;
                MvDecoder_dst_mvx_L1 += dststride;
                MvDecoder_dst_mvy_L1 += dststride;
                MvDecoder_dst_ref_offset_L1 += dststride;
            }
        }


    }



libavcodec/hevc.c:1965
    /**
     * MvDecoder_write_size_buffer
     *
     * @param s HEVC decoding context
     * @param x_off horizontal position of block from origin (0, 0)
     * @param y_off vertical position of block from origin (0, 0)
     * @param log2_cb_size log2 of block size
     * @param cu_byte_size number of bytes used in the bytestream of this CU block.
     */
    static void MvDecoder_write_size_buffer(HEVCContext *s, int x0, int y0,
                                               int log2_cb_size, int cu_byte_size)
    {
        uint8_t *dst = &s->frame->data[9][((y0) >> s->sps->vshift[0]) * s->frame->linesize[0] + \
                               (((x0) >> s->sps->hshift[0]) << s->sps->pixel_shift)];
        ptrdiff_t dststride = s->frame->linesize[0];
        int pb_size = (1 << log2_cb_size);
        int x, y;
        // relative size
        int pb_relative_size = pb_size / 8;
        int bit_density = cu_byte_size * 8 / (pb_relative_size * pb_relative_size);
        //处理x*y个像素
        for (y = 0; y < pb_size; y++) {
            for (x = 0; x < pb_size; x++) {
                //normalization term:
                dst[x] = bit_density;
            }
            dst += dststride;
        }
    }





libavcodec/hevc.c:3941
    uint8_t *MvDecoder_metaBuffer = s->frame->data[10];
    //MvDecoder: Add magic number at the front of the buffer
    MvDecoder_metaBuffer[0] = 4;
    MvDecoder_metaBuffer[1] = 2;
    //MvDecoder: save frame type to buffer

    if(cur_frame->pict_type==AV_PICTURE_TYPE_I) {
        MvDecoder_metaBuffer[2] = 0;
    }
    else if(cur_frame->pict_type==AV_PICTURE_TYPE_P) {
        MvDecoder_metaBuffer[2] = 1;
    }
    else if(cur_frame->pict_type==AV_PICTURE_TYPE_B) {
        MvDecoder_metaBuffer[2] = 2;
    }



libavcodec/hevc.c:3210
    // CTB position x and y.
    x_ctb = FFUMOD(ctb_addr_rs, s->sps->ctb_width) << s->sps->log2_ctb_size;
    y_ctb = FFUDIV(ctb_addr_rs, s->sps->ctb_width) << s->sps->log2_ctb_size;
    //MvDecoder: as index of coding block

libavcodec/hevc.c:3229
    //MvDecoder: get grid index for the CUT quadtree:
    //For each quadtree, need 1+4+16+64=85 bits to save(including PU partition).
    //85 bits = 11 Bytes < 12 Bytes. Use 12 Bytes/u_int_8/u_char to hold one grid.
    //quadtree data start at 1024 bytes onwards
    uint8_t *MvDecoder_ctu_quadtree = s->frame->data[10] + 1024 + ctb_addr_rs*12;


libavcodec/hevc.c:3325
    /*
     * decode quadtree structure
     *
     * in hls_coding_quadtree(HEVCContext *s, int x0, int y0, int log2_cb_size, int cb_depth)：
     * s：HEVCContext
     * x_ctb：CB position x
     * y_ctb：CB position y
     * log2_cb_size：CB size after take log2
     * cb_depth：depth
     */
    //MvDecoder: pass MvDecoder_ctu_quadtree pointer and quadtree_bit_idx to hls_coding_quadtree function.
    more_data = hls_coding_quadtree(s, x_ctb, y_ctb, s->sps->log2_ctb_size, 0, MvDecoder_ctu_quadtree, 0);
    if (more_data < 0) {
        s->tab_slice_address[ctb_addr_rs] = -1;
        return more_data;
    }








libavcodec/hevc.c:2957
/*
 * 解析四叉树结构，并且解码
 * 注意该函数是递归调用
 * 注释和处理：雷霄骅
 *
 *
 * s：HEVCContext上下文结构体
 * x_ctb：CB位置的x坐标
 * y_ctb：CB位置的y坐标
 * log2_cb_size：CB大小取log2之后的值
 * cb_depth：深度
 */
static int hls_coding_quadtree(HEVCContext *s, int x0, int y0,
                               int log2_cb_size, int cb_depth,
                               u_int8_t *MvDecoder_ctu_quadtree,
                               int MvDecoder_quadtree_bit_idx)
{
    /*
     * hls_coding_quadtree()完成了CTU解码工作
     * 函数是一个递归调用的函数，可以按照四叉树的句法格式解析CTU并获得其中的CU。对于每个CU会调用hls_coding_unit()进行解码。
     * hls_coding_unit()会调用hls_prediction_unit()对CU中的PU进行处理。
     *      hls_prediction_unit()调用luma_mc_uni()对亮度单向预测块进行运动补偿处理，
     *                           调用chroma_mc_uni()对色度单向预测块进行运动补偿处理，
     *                           调用luma_mc_bi()对亮度单向预测块进行运动补偿处理。
     *
     * hls_coding_unit()会调用hls_transform_tree()对CU中的TU进行处理。
     * hls_transform_tree()是一个递归调用的函数，可以按照四叉树的句法格式解析并获得其中的TU。
     * 对于每一个TU会调用hls_transform_unit()进行解码。hls_transform_unit()会进行帧内预测，并且调用ff_hevc_hls_residual_coding()解码DCT残差数据。
     */
    HEVCLocalContext *lc = s->HEVClc;

    //CB的大小,split flag=0
    //log2_cb_size为CB大小取log之后的结果
    const int cb_size    = 1 << log2_cb_size;
    int ret;
    int qp_block_mask = (1<<(s->sps->log2_ctb_size - s->pps->diff_cu_qp_delta_depth)) - 1;
    int split_cu_flag;

    //确定CU是否还会划分？
    lc->ct.depth = cb_depth;
    if (x0 + cb_size <= s->sps->width  &&
        y0 + cb_size <= s->sps->height &&
        log2_cb_size > s->sps->log2_min_cb_size) {
        split_cu_flag = ff_hevc_split_coding_unit_flag_decode(s, cb_depth, x0, y0);
    } else {
        split_cu_flag = (log2_cb_size > s->sps->log2_min_cb_size);
    }
    if (s->pps->cu_qp_delta_enabled_flag &&
        log2_cb_size >= s->sps->log2_ctb_size - s->pps->diff_cu_qp_delta_depth) {
        lc->tu.is_cu_qp_delta_coded = 0;
        lc->tu.cu_qp_delta          = 0;
    }

	if (s->sh.cu_chroma_qp_offset_enabled_flag &&
        log2_cb_size >= s->sps->log2_ctb_size - s->pps->diff_cu_chroma_qp_offset_depth) {
        lc->tu.is_cu_chroma_qp_offset_coded = 0;
	}
    if (split_cu_flag) {
        //MvDecoder set split bit of the tree
        MvDecoder_ctu_quadtree[MvDecoder_quadtree_bit_idx / 8] |= (1 << (MvDecoder_quadtree_bit_idx % 8));

        //如果CU还可以继续划分，则继续解析划分后的CU
        //注意这里是递归调用


        //CB的大小,split flag=1
        const int cb_size_split = cb_size >> 1;
        const int x1 = x0 + cb_size_split;
        const int y1 = y0 + cb_size_split;
        /*
         * (x0, y0)  (x1, y0)
		 *     +--------+--------+
		 *     |                 |
		 *     |        |        |
		 *     |                 |
		 *     +  --  --+ --  -- +
		 * (x0, y1)  (x1, y1)    |
		 *     |        |        |
		 *     |                 |
		 *     +--------+--------+
		 *
         */


        int more_data = 0;

        //注意：
        //CU大小减半，log2_cb_size-1
        //深度d加1，cb_depth+1
        //MvDecoder: child bit idx = 4 * MvDecoder_quadtree_grid_idx + 1
        more_data = hls_coding_quadtree(s, x0, y0, log2_cb_size - 1, cb_depth + 1, MvDecoder_ctu_quadtree, 4 * MvDecoder_quadtree_bit_idx + 1);
        if (more_data < 0)
            return more_data;

        if (more_data && x1 < s->sps->width) {
            more_data = hls_coding_quadtree(s, x1, y0, log2_cb_size - 1, cb_depth + 1, MvDecoder_ctu_quadtree, 4 * MvDecoder_quadtree_bit_idx + 2);
            if (more_data < 0)
                return more_data;
        }
        if (more_data && y1 < s->sps->height) {
            more_data = hls_coding_quadtree(s, x0, y1, log2_cb_size - 1, cb_depth + 1, MvDecoder_ctu_quadtree, 4 * MvDecoder_quadtree_bit_idx + 3);
            if (more_data < 0)
                return more_data;
        }
        if (more_data && x1 < s->sps->width &&
            y1 < s->sps->height) {
            more_data = hls_coding_quadtree(s, x1, y1, log2_cb_size - 1, cb_depth + 1, MvDecoder_ctu_quadtree, 4 * MvDecoder_quadtree_bit_idx + 4);
            if (more_data < 0)
                return more_data;
        }

        if(((x0 + (1<<log2_cb_size)) & qp_block_mask) == 0 &&
            ((y0 + (1<<log2_cb_size)) & qp_block_mask) == 0)
            lc->qPy_pred = lc->qp_y;

        if (more_data)
            return ((x1 + cb_size_split) < s->sps->width ||
                    (y1 + cb_size_split) < s->sps->height);
        else
            return 0;
    } else {

        /*
         * (x0, y0)
		 *     +--------+--------+
		 *     |                 |
		 *     |                 |
		 *     |                 |
		 *     +                 +
		 *     |                 |
		 *     |                 |
		 *     |                 |
		 *     +--------+--------+
         *
         */
        //注意处理的是不可划分的CU单元
        //处理CU单元-真正的解码
        ret = hls_coding_unit(s, x0, y0, log2_cb_size, MvDecoder_ctu_quadtree, MvDecoder_quadtree_bit_idx);
        if (ret < 0)
            return ret;
        if ((!((x0 + cb_size) &
               ((1 << (s->sps->log2_ctb_size))) - 1) ||
             (x0 + cb_size >= s->sps->width)) &&
            (!((y0 + cb_size) &
               ((1 << (s->sps->log2_ctb_size))) - 1) ||
             (y0 + cb_size >= s->sps->height))) {
            int end_of_slice_flag = ff_hevc_end_of_slice_flag_decode(s);
            return !end_of_slice_flag;
        } else {
            return 1;
        }
    }

    return 0;
}
/* 从源代码可以看出，hls_coding_quadtree()首先调用ff_hevc_split_coding_unit_flag_decode()判断当前CU是否还需要划分。
 * 如果需要划分的话，就会递归调用4次hls_coding_quadtree()分别对4个子块继续进行四叉树解析；
 * 如果不需要划分，就会调用hls_coding_unit()对CU进行解码。
 * 总而言之，hls_coding_quadtree()会解析出来一个CTU中的所有CU，并且对每一个CU逐一调用hls_coding_unit()进行解码。
 * 一个CTU中CU的解码顺序如下图所示。图中a, b, c …即代表了的先后顺序。
 * https://img-blog.csdn.net/20150613173036048
*/



libavcodec/hevc.c:2604
//处理CU单元-真正的解码
static int hls_coding_unit(HEVCContext *s, int x0, int y0, int log2_cb_size, u_int8_t *MvDecoder_ctu_quadtree, int MvDecoder_quadtree_bit_idx)
{
    /* （1）调用hls_prediction_unit()处理PU。
     * （2）调用hls_transform_tree()处理TU树
    */
     //CB大小
    int cb_size          = 1 << log2_cb_size;
    HEVCLocalContext *lc = s->HEVClc;

    // MvDevoder: bytestream checkpoint of the start of cu
    uint8_t* bytestream_last = lc->cc.bytestream;

    int log2_min_cb_size = s->sps->log2_min_cb_size;
    int length           = cb_size >> log2_min_cb_size;
    int min_cb_width     = s->sps->min_cb_width;

    //以最小的CB为单位（例如4x4）的时候，当前CB的位置——x坐标和y坐标
    int x_cb             = x0 >> log2_min_cb_size;
    int y_cb             = y0 >> log2_min_cb_size;
    int idx              = log2_cb_size - 2;
    int qp_block_mask    = (1<<(s->sps->log2_ctb_size - s->pps->diff_cu_qp_delta_depth)) - 1;
    int x, y, ret;

    //设置CU的属性值
    lc->cu.x                = x0;
    lc->cu.y                = y0;
    lc->cu.rqt_root_cbf     = 1;
    lc->cu.pred_mode        = MODE_INTRA;
    lc->cu.part_mode        = PART_2Nx2N;
    lc->cu.intra_split_flag = 0;
    lc->cu.pcm_flag         = 0;

    //int bytestream_pu;
    //int bytestream_tu;
    SAMPLE_CTB(s->skip_flag, x_cb, y_cb) = 0;
    for (x = 0; x < 4; x++)
        lc->pu.intra_pred_mode[x] = 1;
    if (s->pps->transquant_bypass_enable_flag) {
        lc->cu.cu_transquant_bypass_flag = ff_hevc_cu_transquant_bypass_flag_decode(s);
        if (lc->cu.cu_transquant_bypass_flag)
            set_deblocking_bypass(s, x0, y0, log2_cb_size);
    } else
        lc->cu.cu_transquant_bypass_flag = 0;

    if (s->sh.slice_type != I_SLICE) {
        //Skip类型
        uint8_t skip_flag = ff_hevc_skip_flag_decode(s, x0, y0, x_cb, y_cb);
        //设置到skip_flag缓存中
        x = y_cb * min_cb_width + x_cb;
        for (y = 0; y < length; y++) {
            memset(&s->skip_flag[x], skip_flag, length);
            x += min_cb_width;
        }
        lc->cu.pred_mode = skip_flag ? MODE_SKIP : MODE_INTER;
    } else {
        x = y_cb * min_cb_width + x_cb;
        for (y = 0; y < length; y++) {
            memset(&s->skip_flag[x], 0, length);
            x += min_cb_width;
        }
    }

    if (SAMPLE_CTB(s->skip_flag, x_cb, y_cb)) {
        hls_prediction_unit(s, x0, y0, cb_size, cb_size, log2_cb_size, 0, idx);
        intra_prediction_unit_default_value(s, x0, y0, log2_cb_size);

        if (!s->sh.disable_deblocking_filter_flag)
            ff_hevc_deblocking_boundary_strengths(s, x0, y0, log2_cb_size);
    } else {
        //读取预测模式（非 I Slice）
        if (s->sh.slice_type != I_SLICE)
            lc->cu.pred_mode = ff_hevc_pred_mode_decode(s);
        //不是帧内预测模式的时候
        //或者已经是最小CB的时候
        if (lc->cu.pred_mode != MODE_INTRA ||
            log2_cb_size == s->sps->log2_min_cb_size) {
            lc->cu.part_mode        = ff_hevc_part_mode_decode(s, log2_cb_size);
            lc->cu.intra_split_flag = lc->cu.part_mode == PART_NxN &&
                                      lc->cu.pred_mode == MODE_INTRA;
        }

        if (lc->cu.pred_mode == MODE_INTRA) {
            //帧内预测模式

            //PCM方式编码，不常见
            if (lc->cu.part_mode == PART_2Nx2N && s->sps->pcm_enabled_flag &&
                log2_cb_size >= s->sps->pcm.log2_min_pcm_cb_size &&
                log2_cb_size <= s->sps->pcm.log2_max_pcm_cb_size) {
                lc->cu.pcm_flag = ff_hevc_pcm_flag_decode(s);
            }
            if (lc->cu.pcm_flag) {
                intra_prediction_unit_default_value(s, x0, y0, log2_cb_size);
                ret = hls_pcm_sample(s, x0, y0, log2_cb_size);
                if (s->sps->pcm.loop_filter_disable_flag)
                    set_deblocking_bypass(s, x0, y0, log2_cb_size);

                if (ret < 0)
                    return ret;
            } else {
                //获取帧内预测模式
                intra_prediction_unit(s, x0, y0, log2_cb_size);
            }

        } else {
            //帧间预测模式
            intra_prediction_unit_default_value(s, x0, y0, log2_cb_size);

            //帧间模式一共有8种划分模式
            //uint8_t* bytestream_before_pu = lc->cc.bytestream;
            switch (lc->cu.part_mode) {
            case PART_2Nx2N:
                /*
				 * PART_2Nx2N:
				 * +--------+--------+
				 * |                 |
				 * |                 |
				 * |                 |
				 * +        +        +
				 * |                 |
				 * |                 |
				 * |                 |
				 * +--------+--------+
            	 */
                //处理PU单元-运动补偿
                hls_prediction_unit(s, x0, y0, cb_size, cb_size, log2_cb_size, 0, idx);
                break;
            case PART_2NxN:

                /*
    			 * PART_2NxN:
    			 * +--------+--------+
    			 * |                 |
    			 * |                 |
    			 * |                 |
    			 * +--------+--------+
    			 * |                 |
    			 * |                 |
    			 * |                 |
    			 * +--------+--------+
    			 *
                 */
                /*
                 * hls_prediction_unit()参数：
                 * x0 : PU左上角x坐标
                 * y0 : PU左上角y坐标
                 * nPbW : PU宽度
                 * nPbH : PU高度
                 * log2_cb_size : CB大小取log2()的值
                 * partIdx : PU的索引号-分成4个块的时候取0-3，分成两个块的时候取0和1
                 */

                //上
                hls_prediction_unit(s, x0, y0,               cb_size, cb_size / 2, log2_cb_size, 0, idx);
                //下
                hls_prediction_unit(s, x0, y0 + cb_size / 2, cb_size, cb_size / 2, log2_cb_size, 1, idx);

                //MvDecoder_ctu_quadtree[MvDecoder_quadtree_bit_idx / 8] |= (1 << (MvDecoder_quadtree_bit_idx % 8));
                break;
            case PART_Nx2N:
                /*
    			 * PART_Nx2N:
    			 * +--------+--------+
    			 * |        |        |
    			 * |        |        |
    			 * |        |        |
    			 * +        +        +
    			 * |        |        |
    			 * |        |        |
    			 * |        |        |
    			 * +--------+--------+
    			 *
                 */
                //左
                hls_prediction_unit(s, x0,               y0, cb_size / 2, cb_size, log2_cb_size, 0, idx - 1);
                //右
                hls_prediction_unit(s, x0 + cb_size / 2, y0, cb_size / 2, cb_size, log2_cb_size, 1, idx - 1);

                //MvDecoder_ctu_quadtree[MvDecoder_quadtree_bit_idx / 8] |= (1 << (MvDecoder_quadtree_bit_idx % 8));
                break;
            case PART_2NxnU:

                /*
    			 * PART_2NxnU (Upper) :
    			 * +--------+--------+
    			 * |                 |
    			 * +--------+--------+
    			 * |                 |
    			 * +        +        +
    			 * |                 |
    			 * |                 |
    			 * |                 |
    			 * +--------+--------+
    			 *
                 */

                //上
                hls_prediction_unit(s, x0, y0,               cb_size, cb_size     / 4, log2_cb_size, 0, idx);
                //下
                hls_prediction_unit(s, x0, y0 + cb_size / 4, cb_size, cb_size * 3 / 4, log2_cb_size, 1, idx);


                //MvDecoder_ctu_quadtree[MvDecoder_quadtree_bit_idx / 8] |= (1 << (MvDecoder_quadtree_bit_idx % 8));
                break;
            case PART_2NxnD:
                /*
    			 * PART_2NxnD (Down) :
    			 * +--------+--------+
    			 * |                 |
    			 * |                 |
    			 * |                 |
    			 * +        +        +
    			 * |                 |
    			 * +--------+--------+
    			 * |                 |
    			 * +--------+--------+
    			 *
                 */

                //上
                hls_prediction_unit(s, x0, y0,                   cb_size, cb_size * 3 / 4, log2_cb_size, 0, idx);
                //下
                hls_prediction_unit(s, x0, y0 + cb_size * 3 / 4, cb_size, cb_size     / 4, log2_cb_size, 1, idx);


                //MvDecoder_ctu_quadtree[MvDecoder_quadtree_bit_idx / 8] |= (1 << (MvDecoder_quadtree_bit_idx % 8));
                break;
            case PART_nLx2N:
                /*
                 * PART_nLx2N (Left):
                 * +----+---+--------+
                 * |    |            |
                 * |    |            |
                 * |    |            |
                 * +    +   +        +
                 * |    |            |
                 * |    |            |
                 * |    |            |
                 * +----+---+--------+
                 *
                 */

                //左
                hls_prediction_unit(s, x0,               y0, cb_size     / 4, cb_size, log2_cb_size, 0, idx - 2);
                //右
                hls_prediction_unit(s, x0 + cb_size / 4, y0, cb_size * 3 / 4, cb_size, log2_cb_size, 1, idx - 2);

                //MvDecoder_ctu_quadtree[MvDecoder_quadtree_bit_idx / 8] |= (1 << (MvDecoder_quadtree_bit_idx % 8));
                break;
            case PART_nRx2N:

                /*
    			 * PART_nRx2N (Right):
    			 * +--------+---+----+
    			 * |            |    |
    			 * |            |    |
    			 * |            |    |
    			 * +        +   +    +
    			 * |            |    |
    			 * |            |    |
    			 * |            |    |
    			 * +--------+---+----+
    			 *
                 */

                //左
                hls_prediction_unit(s, x0,                   y0, cb_size * 3 / 4, cb_size, log2_cb_size, 0, idx - 2);
                //右
                hls_prediction_unit(s, x0 + cb_size * 3 / 4, y0, cb_size     / 4, cb_size, log2_cb_size, 1, idx - 2);

                //MvDecoder_ctu_quadtree[MvDecoder_quadtree_bit_idx / 8] |= (1 << (MvDecoder_quadtree_bit_idx % 8));

                break;
            case PART_NxN:

                /*
    			 * PART_NxN:
    			 * +--------+--------+
    			 * |        |        |
    			 * |        |        |
    			 * |        |        |
    			 * +--------+--------+
    			 * |        |        |
    			 * |        |        |
    			 * |        |        |
    			 * +--------+--------+
    			 *
                 */
                //MvDecoder set split bit of the tree

                hls_prediction_unit(s, x0,               y0,               cb_size / 2, cb_size / 2, log2_cb_size, 0, idx - 1);
                hls_prediction_unit(s, x0 + cb_size / 2, y0,               cb_size / 2, cb_size / 2, log2_cb_size, 1, idx - 1);
                hls_prediction_unit(s, x0,               y0 + cb_size / 2, cb_size / 2, cb_size / 2, log2_cb_size, 2, idx - 1);
                hls_prediction_unit(s, x0 + cb_size / 2, y0 + cb_size / 2, cb_size / 2, cb_size / 2, log2_cb_size, 3, idx - 1);
                //MvDecoder_ctu_quadtree[MvDecoder_quadtree_bit_idx / 8] |= (1 << (MvDecoder_quadtree_bit_idx % 8));

                break;
            }
            //bytestream_pu = lc->cc.bytestream-bytestream_before_pu;
        }

        if (!lc->cu.pcm_flag) {
            if (lc->cu.pred_mode != MODE_INTRA &&
                !(lc->cu.part_mode == PART_2Nx2N && lc->pu.merge_flag)) {
                lc->cu.rqt_root_cbf = ff_hevc_no_residual_syntax_flag_decode(s);
            }
            if (lc->cu.rqt_root_cbf) {
                const static int cbf[2] = { 0 };
                lc->cu.max_trafo_depth = lc->cu.pred_mode == MODE_INTRA ?
                                         s->sps->max_transform_hierarchy_depth_intra + lc->cu.intra_split_flag :
                                         s->sps->max_transform_hierarchy_depth_inter;
                //处理TU四叉树
                //uint8_t* bytestream_before_tu = lc->cc.bytestream;
                ret = hls_transform_tree(s, x0, y0, x0, y0, x0, y0,
                                         log2_cb_size,
                                         log2_cb_size, 0, 0, cbf, cbf);
                //bytestream_tu = lc->cc.bytestream-bytestream_before_tu;
                if (ret < 0)
                    return ret;
            } else {
                if (!s->sh.disable_deblocking_filter_flag)
                    ff_hevc_deblocking_boundary_strengths(s, x0, y0, log2_cb_size);
            }
        }
    }

    if (s->pps->cu_qp_delta_enabled_flag && lc->tu.is_cu_qp_delta_coded == 0)
        ff_hevc_set_qPy(s, x0, y0, log2_cb_size);

    x = y_cb * min_cb_width + x_cb;
    for (y = 0; y < length; y++) {
        memset(&s->qp_y_tab[x], lc->qp_y, length);
        x += min_cb_width;
    }

    if(((x0 + (1<<log2_cb_size)) & qp_block_mask) == 0 &&
       ((y0 + (1<<log2_cb_size)) & qp_block_mask) == 0) {
        lc->qPy_pred = lc->qp_y;
    }

    set_ct_depth(s, x0, y0, log2_cb_size, lc->ct.depth);

    // MvDevoder: bytestream checkpoint of the start of cu
    // Get size information from CABAC context
    int bytes_size_cu = lc->cc.bytestream - bytestream_last;
    //int bytes_pu_tu = bytestream_pu + bytestream_tu;
    // MvDeocder: fill totalByteSize of this CU.
    MvDecoder_write_size_buffer(s, x0, y0, log2_cb_size, bytes_size_cu);

    return 0;
}










STEP3: print buffer to result


gpac/modules/openhevc_dec/openHevcWrapper.h:72
typedef struct OpenHevc_Frame_cpy
{
   void*        pvY;
   void*        pvU;
   void*        pvV;
   //MvDecoder
   void*        pvMVX_L0;
   void*        pvMVY_L0;
   void*        pvMVX_L1;
   void*        pvMVY_L1;
   void*        pvREF_OFF_L0;
   void*        pvREF_OFF_L1;
   void*        pvSize;
   void*        pvMeta;


   OpenHevc_FrameInfo frameInfo;
} OpenHevc_Frame_cpy;

main_hm/main.c:195
    //MvDecoder
    openHevcFrameCpy.pvMVX_L0 = NULL;
    openHevcFrameCpy.pvMVY_L0 = NULL;
    openHevcFrameCpy.pvMVX_L1 = NULL;
    openHevcFrameCpy.pvMVY_L1 = NULL;
    openHevcFrameCpy.pvREF_OFF_L0 = NULL;
    openHevcFrameCpy.pvREF_OFF_L1 = NULL;
    openHevcFrameCpy.pvMeta = NULL;
    openHevcFrameCpy.pvSize = NULL;

main_hm/main.c:259
    //MvDecoder
    free(openHevcFrameCpy.pvMVX_L0);
    free(openHevcFrameCpy.pvMVY_L0);
    free(openHevcFrameCpy.pvMVX_L1);
    free(openHevcFrameCpy.pvMVY_L1);
    free(openHevcFrameCpy.pvREF_OFF_L0);
    free(openHevcFrameCpy.pvREF_OFF_L1);
    free(openHevcFrameCpy.pvMeta);
    free(openHevcFrameCpy.pvSize);

main_hm/main.c:272
    //MvDecoder
    openHevcFrameCpy.pvMVX_L0 = calloc (openHevcFrameCpy.frameInfo.nYPitch * openHevcFrameCpy.frameInfo.nHeight * 2, sizeof(unsigned char));
    openHevcFrameCpy.pvMVY_L0 = calloc (openHevcFrameCpy.frameInfo.nYPitch * openHevcFrameCpy.frameInfo.nHeight * 2, sizeof(unsigned char));
    openHevcFrameCpy.pvMVX_L1 = calloc (openHevcFrameCpy.frameInfo.nYPitch * openHevcFrameCpy.frameInfo.nHeight * 2, sizeof(unsigned char));
    openHevcFrameCpy.pvMVY_L1 = calloc (openHevcFrameCpy.frameInfo.nYPitch * openHevcFrameCpy.frameInfo.nHeight * 2, sizeof(unsigned char));
    openHevcFrameCpy.pvREF_OFF_L0 = calloc (openHevcFrameCpy.frameInfo.nYPitch * openHevcFrameCpy.frameInfo.nHeight, sizeof(unsigned char));
    openHevcFrameCpy.pvREF_OFF_L1 = calloc (openHevcFrameCpy.frameInfo.nYPitch * openHevcFrameCpy.frameInfo.nHeight, sizeof(unsigned char));
    openHevcFrameCpy.pvSize = calloc (openHevcFrameCpy.frameInfo.nYPitch * openHevcFrameCpy.frameInfo.nHeight, sizeof(unsigned char));
    openHevcFrameCpy.pvMeta = calloc (8192, sizeof(unsigned char));

main_hm/main.c:284
   if (fout) {
       int format = openHevcFrameCpy.frameInfo.chromat_format == YUV420 ? 1 : 0;
       libOpenHevcGetOutputCpy(openHevcHandle, 1, &openHevcFrameCpy);
       fwrite( openHevcFrameCpy.pvMeta , sizeof(uint8_t) , 8192, fout);

       fwrite( openHevcFrameCpy.pvY , sizeof(uint8_t) , openHevcFrameCpy.frameInfo.nYPitch * openHevcFrameCpy.frameInfo.nHeight, fout);
       fwrite( openHevcFrameCpy.pvU , sizeof(uint8_t) , openHevcFrameCpy.frameInfo.nUPitch * openHevcFrameCpy.frameInfo.nHeight >> format, fout);
       fwrite( openHevcFrameCpy.pvV , sizeof(uint8_t) , openHevcFrameCpy.frameInfo.nVPitch * openHevcFrameCpy.frameInfo.nHeight >> format, fout);
       //MvDecoder
       fwrite( openHevcFrameCpy.pvMVX_L0 , sizeof(uint8_t) , openHevcFrameCpy.frameInfo.nYPitch * openHevcFrameCpy.frameInfo.nHeight * 2, fout);
       fwrite( openHevcFrameCpy.pvMVY_L0 , sizeof(uint8_t) , openHevcFrameCpy.frameInfo.nYPitch * openHevcFrameCpy.frameInfo.nHeight * 2, fout);
       fwrite( openHevcFrameCpy.pvMVX_L1 , sizeof(uint8_t) , openHevcFrameCpy.frameInfo.nYPitch * openHevcFrameCpy.frameInfo.nHeight * 2, fout);
       fwrite( openHevcFrameCpy.pvMVY_L1 , sizeof(uint8_t) , openHevcFrameCpy.frameInfo.nYPitch * openHevcFrameCpy.frameInfo.nHeight * 2, fout);
       fwrite( openHevcFrameCpy.pvREF_OFF_L0 , sizeof(uint8_t) , openHevcFrameCpy.frameInfo.nYPitch * openHevcFrameCpy.frameInfo.nHeight, fout);
       fwrite( openHevcFrameCpy.pvREF_OFF_L1 , sizeof(uint8_t) , openHevcFrameCpy.frameInfo.nYPitch * openHevcFrameCpy.frameInfo.nHeight, fout);
       fwrite( openHevcFrameCpy.pvSize , sizeof(uint8_t) , openHevcFrameCpy.frameInfo.nYPitch * openHevcFrameCpy.frameInfo.nHeight, fout);

   }





gpac/modules/openhevc_dec/openHevcWrapper.c:366
        //MvDecoder
        unsigned char *MVX_L0 = (unsigned char *) openHevcFrame->pvMVX_L0;
        unsigned char *MVY_L0 = (unsigned char *) openHevcFrame->pvMVY_L0;
        unsigned char *MVX_L1 = (unsigned char *) openHevcFrame->pvMVX_L1;
        unsigned char *MVY_L1 = (unsigned char *) openHevcFrame->pvMVY_L1;
        unsigned char *REF_OFF_L0 = (unsigned char *) openHevcFrame->pvREF_OFF_L0;
        unsigned char *REF_OFF_L1 = (unsigned char *) openHevcFrame->pvREF_OFF_L1;
        unsigned char *Meta = (unsigned char *) openHevcFrame->pvMeta;
        unsigned char *Size = (unsigned char *) openHevcFrame->pvSize;



gpac/modules/openhevc_dec/openHevcWrapper.c:406
        //MvDecoder
        memcpy(Meta, openHevcContext->picture->data[10], 8192);
        memset(openHevcContext->picture->data[10],0,8192); // clean the buffer